{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6025b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from char_converter import CharConverter\n",
    "converter = CharConverter('v2t')\n",
    "def convert(text):\n",
    "    return converter.convert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfa91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sort_titles:\n",
    "    def __init__(self, dataframe, column_names=[\"c_title_chn\", \"c_textid\", \"c_name_chn\", \"c_personid\", \"row_id\"]):\n",
    "        # must have at least the five columns\n",
    "        # c_textid is in fact not needed, but keep it for now\n",
    "        # c_textid is NOT unique (one text with multiple authors), and thus the row_id is necessary\n",
    "        self.dtf = dataframe\n",
    "        self.cols = column_names\n",
    "        \n",
    "    def get_sorted_choices(self, byid=False):\n",
    "        self.dict_by_author = {} \n",
    "        # a nested dictionary\n",
    "        # first layer: key=author or authorid, val=dict\n",
    "        # second layer: key=(rowid, textid), val=title\n",
    "        for _, row in self.dtf.iterrows():\n",
    "            author = str(row[self.cols[2]])\n",
    "            authorid = int(row[self.cols[3]])\n",
    "            title = str(row[self.cols[0]])\n",
    "            titleid = int(row[self.cols[1]])\n",
    "            rowid = int(row[self.cols[4]])\n",
    "            if byid:\n",
    "                if authorid not in self.dict_by_author:\n",
    "                    self.dict_by_author[authorid] = {}\n",
    "                self.dict_by_author[authorid][(rowid, titleid)] = title\n",
    "            else:\n",
    "                if author not in self.dict_by_author:\n",
    "                    self.dict_by_author[author] = {}\n",
    "                self.dict_by_author[author][(rowid, titleid)] = title\n",
    "        return self.dict_by_author\n",
    "    \n",
    "    def get_all_choices(self):\n",
    "        self.dtf = self.dtf.astype({self.cols[4]: int, self.cols[1]: int, self.cols[0]: str})\n",
    "        self.dict_all_titles = self.dtf.set_index([self.cols[4], self.cols[1]])[self.cols[0]].to_dict()\n",
    "        return self.dict_all_titles # a simple dictionary, not nested\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3357f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fuzzy match by char as an alternative scorer\n",
    "\n",
    "def compare_chars(char_1, char_2):\n",
    "    char_1_set = set(char_1)\n",
    "    char_1_set_len = len(char_1_set)\n",
    "    char_2_set = set(char_2)\n",
    "    char_2_set_len = len(char_2_set)\n",
    "    intersection_set = char_1_set.intersection(char_2_set)\n",
    "    intersection_set_len = len(intersection_set)\n",
    "    if(char_1_set_len != 0 and char_2_set_len != 0):\n",
    "        max_rate = max(intersection_set_len/char_1_set_len, intersection_set_len/char_2_set_len)\n",
    "    else:\n",
    "        max_rate = 0\n",
    "    return [intersection_set_len, max_rate, \";\".join(intersection_set)]\n",
    "\n",
    "def compare_chars_scorer(s1, s2, **kwargs):\n",
    "    result = compare_chars(s1, s2)\n",
    "    \n",
    "    return result[1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ba5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up by author name, not id\n",
    "# filter the compare table by dynasty first\n",
    "def fuzzy_lookup_by_name(dfleft, dfright, right_cols=[\"c_title_chn\", \"c_textid\", \"c_name_chn\", \"c_personid\", \"row_id\"], left_cols=[\"internalindex\",\"title\",\"author\"], scorer=fuzz.WRatio, score_cutoff=75):\n",
    "    # try also scorer = fuzz.token_set_ratio, compare_chars_scorer\n",
    "    results = [] # the final values to be converted to df\n",
    "\n",
    "    # sort the compare table\n",
    "    df2 = sort_titles(dfright, column_names=right_cols)\n",
    "    # create the nested dict, key=author, val=dict{key=(rowid,textid),val=title}\n",
    "    titles_by_author = df2.get_sorted_choices(byid=False)\n",
    "    choices = {} # decide by condition which dict to create\n",
    "\n",
    "    for _, row in dfleft.iterrows():\n",
    "        index = row[left_cols[0]]\n",
    "        title = row[left_cols[1]]\n",
    "        author = row[left_cols[2]]\n",
    "        flag = \"\"\n",
    "        if author in titles_by_author:\n",
    "            if author == \"未詳\":\n",
    "                flag = \"anon work\" # excluded from the automated doublecheck\n",
    "            else:\n",
    "                flag = \"author matched\"\n",
    "            choices = titles_by_author[author]\n",
    "        else:\n",
    "            flag = \"no match of author\"\n",
    "            choices = df2.get_all_choices() \n",
    "            # here the rowid matters\n",
    "            # it may match titles by the same author, but the author names do not match due to character variants or errors\n",
    "\n",
    "        # returns a list of tuples: [(match_title, score, (rowid,textid)),etc], or NoneType\n",
    "        matches = process.extract(title, choices, scorer=scorer, limit=None, score_cutoff=score_cutoff)\n",
    "\n",
    "        # doublecheck whether an authored title == an anon title in CBDB\n",
    "        if (not matches) and (flag == \"author matched\"):\n",
    "            doublecheck = titles_by_author[\"未詳\"]\n",
    "            matches = process.extract(title, doublecheck, scorer=scorer, limit=None, score_cutoff=score_cutoff)\n",
    "            if matches:\n",
    "                flag = \"author matched but text from anon works\"\n",
    "        \n",
    "        # write values\n",
    "        if matches:\n",
    "            for match_title, score, ids in matches:\n",
    "                rowid = ids[0]\n",
    "                textid = ids[1]\n",
    "                results.append({\n",
    "                    \"internalindex\": index, \n",
    "                    \"title\": title,\n",
    "                    \"authorname\": author,\n",
    "                    \"best_match_title\": match_title,\n",
    "                    \"best_match_textid\": textid,\n",
    "                    \"row_id\": rowid,\n",
    "                    \"notes\": flag,\n",
    "                    \"score\": score\n",
    "                    })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"internalindex\": index,\n",
    "                \"title\": title,\n",
    "                \"authorname\": author,\n",
    "                \"best_match_title\": None,\n",
    "                \"best_match_textid\": None,\n",
    "                \"row_id\": None,\n",
    "                \"notes\": flag,\n",
    "                \"score\": None\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb050cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up by author id, and check against anon works\n",
    "def fuzzy_lookup_by_id(dfleft, dfright, right_cols=[\"c_title_chn\", \"c_textid\", \"c_name_chn\", \"c_personid\", \"row_id\"], left_cols=[\"internalindex\",\"title\",\"authorid\"], scorer=fuzz.WRatio, score_cutoff=75):\n",
    "    # try also scorer = fuzz.token_set_ratio, compare_chars_scorer\n",
    "    df2 = sort_titles(dfright, column_names=right_cols)\n",
    "    results = []\n",
    "    titles_by_author = df2.get_sorted_choices(byid=True) # the nested dict\n",
    "    choices = {} # decide by condition which dict to create\n",
    "    for _, row in dfleft.iterrows():\n",
    "        index = row[left_cols[0]]\n",
    "        title = row[left_cols[1]]\n",
    "        author = row[left_cols[2]]\n",
    "        flag = \"\"\n",
    "        if author in titles_by_author:\n",
    "            if author == 0:\n",
    "                flag = \"check\" # excluded from the automated doublecheck\n",
    "            else:\n",
    "                flag = \"author matched\"\n",
    "            choices = titles_by_author[author]\n",
    "        else:\n",
    "            flag = \"no match of author\"\n",
    "            choices = titles_by_author[0] # unlike filter by author name, no need to check against everything\n",
    "\n",
    "        # returns a list of tuples: [(match_title, score, (rowid,textid)), etc], or NoneType\n",
    "        matches = process.extract(title, choices, scorer=scorer, limit=None, score_cutoff=score_cutoff)\n",
    "\n",
    "        # doublecheck whether an authored title == an anon title in CBDB\n",
    "        if (not matches) and (flag == \"author matched\"):\n",
    "            doublecheck = titles_by_author[0]\n",
    "            matches = process.extract(title, doublecheck, scorer=scorer, limit=None, score_cutoff=score_cutoff)\n",
    "            if matches:\n",
    "                flag = \"author matched but text from anon works\"\n",
    "        \n",
    "        # write values\n",
    "        if matches:\n",
    "            for match_title, score, ids in matches:\n",
    "                rowid = ids[0] \n",
    "                textid = ids[1]\n",
    "                results.append({\n",
    "                    \"internalindex\": index, \n",
    "                    \"title\": title,\n",
    "                    \"authorid\": author,\n",
    "                    \"best_match_title\": match_title,\n",
    "                    \"best_match_textid\": textid,\n",
    "                    \"row_id\": rowid,\n",
    "                    \"notes\": flag,\n",
    "                    \"score\": score\n",
    "                    })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"internalindex\": index,\n",
    "                \"title\": title,\n",
    "                \"authorid\": author,\n",
    "                \"best_match_title\": None,\n",
    "                \"best_match_textid\": None,\n",
    "                \"row_id\": None,\n",
    "                \"notes\": flag,\n",
    "                \"score\": None\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11175064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple fuzzy match, do not check against anon works\n",
    "def fuzzy_lookup_simple_id(dfleft, dfright, right_cols=[\"c_title_chn\", \"c_textid\", \"c_name_chn\", \"c_personid\", \"row_id\"], left_cols=[\"internalindex\",\"title\",\"authorid\"], scorer=fuzz.WRatio, score_cutoff=75):\n",
    "    # try also scorer = fuzz.token_set_ratio, compare_chars_scorer\n",
    "    df2 = sort_titles(dfright, column_names=right_cols)\n",
    "    results = []\n",
    "    titles_by_author = df2.get_sorted_choices(byid=True) # the nested dict\n",
    "    choices = {} # decide by condition which dict to create\n",
    "    for _, row in dfleft.iterrows():\n",
    "        index = row[left_cols[0]]\n",
    "        title = row[left_cols[1]]\n",
    "        author = row[left_cols[2]]\n",
    "        flag = \"\"\n",
    "        if author in titles_by_author:\n",
    "            flag = \"author matched\"\n",
    "            choices = titles_by_author[author]\n",
    "            # returns a list of tuples: [(match_title, score, (rowid,textid))], or NoneType\n",
    "            matches = process.extract(title, choices, scorer=scorer, limit=None, score_cutoff=score_cutoff)\n",
    "        else:\n",
    "            matches = None\n",
    "            flag = \"no match of author\"\n",
    "        \n",
    "        # write values\n",
    "        if matches:\n",
    "            for match_title, score, ids in matches:\n",
    "                rowid = ids[0]\n",
    "                textid = ids[1]\n",
    "                results.append({\n",
    "                    \"internalindex\": index,\n",
    "                    \"title\": title,\n",
    "                    \"authorid\": author,\n",
    "                    \"best_match_title\": match_title,\n",
    "                    \"best_match_textid\": textid,\n",
    "                    \"row_id\": rowid,\n",
    "                    \"notes\": flag,\n",
    "                    \"score\": score\n",
    "                    })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"internalindex\": index,\n",
    "                \"title\": title,\n",
    "                \"authorid\": author,\n",
    "                \"best_match_title\": None,\n",
    "                \"best_match_textid\": None,\n",
    "                \"row_id\": None,\n",
    "                \"notes\": flag,\n",
    "                \"score\": None\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40d0135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorderdf (df1, df2, targetcol, mergeon):\n",
    "    '''adjust column orders after merging two dfs\n",
    "    df1 is the merged df (big), df2 is the added df (small)\n",
    "    insert everything in df2 before the targetcol\n",
    "    return a new df'''\n",
    "    cols_to_move = [col for col in df2 if col != mergeon]\n",
    "    all_cols = list(df1.columns)\n",
    "    for col in cols_to_move:\n",
    "        all_cols.remove(col)\n",
    "    insert_pos = all_cols.index(targetcol)\n",
    "    newcol_list = all_cols[:insert_pos] + cols_to_move + all_cols[insert_pos:]\n",
    "    reordered = df1[newcol_list]\n",
    "    return reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cced60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_merge(func, inputtable, comparetable, comparecols, inputcols, scorer, score_cutoff):\n",
    "    result = func(inputtable, comparetable, right_cols=comparecols, left_cols=inputcols, scorer=scorer, score_cutoff=score_cutoff)\n",
    "    if func == fuzzy_lookup_by_name:\n",
    "        inputtable_cleaned = inputtable.drop(columns=[\"title\",\"authorname\"])\n",
    "    else:\n",
    "        inputtable_cleaned = inputtable.drop(columns=[\"title\",\"authorid\"])\n",
    "    comparetable_cleaned = comparetable.drop(columns=[\"c_title_chn\", \"c_textid\"])\n",
    "    # join the comparetable and adjust the order\n",
    "    mergestep = pd.merge(result, comparetable_cleaned, on=\"row_id\", how=\"left\")\n",
    "    reordered = reorderdf(mergestep, comparetable_cleaned, \"notes\", \"row_id\")\n",
    "    # join the original table\n",
    "    mergefurther = pd.merge(reordered, inputtable_cleaned, on=\"internalindex\", how=\"left\")\n",
    "    reordered_further = reorderdf(mergefurther, inputtable_cleaned, \"best_match_title\", \"internalindex\")\n",
    "    merge = reordered_further.drop(columns=[\"row_id\"])\n",
    "    merge.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3656f54",
   "metadata": {},
   "source": [
    "The values in the following four can be modified if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare against the table from the latest.db, run the py file first\n",
    "comparetablename = \"JOINED_BIOG_TEXT.xlsx\"\n",
    "comparetable = pd.read_excel(comparetablename, sheet_name=0) \n",
    "comparecols=[\"c_title_chn\", \"c_textid\", \"c_name_chn\", \"c_personid\",\"row_id\"] # change column headers if necessary\n",
    "\n",
    "run_char = 1\n",
    "\n",
    "inputtable = pd.read_excel(\"input.xlsx\", sheet_name=0) # change file name if necessary\n",
    "inputcols = [\"internalindex\",\"title\",\"authorid\"] # change column headers if necessary\n",
    "# inputcols = [\"internalindex\",\"title\",\"authorname\"] # match by author name; filter by dynasties first\n",
    "if run_char == 1:\n",
    "    inputtable[\"title\"] = inputtable[\"title\"].astype(str).apply(convert)\n",
    "    # inputtable[\"authorname\"] = inputtable[\"authorname\"].astype(str).apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = fuzz.WRatio # for higher accuracy\n",
    "# scorer = compare_chars_scorer # for higher sensitivity\n",
    "score_cutoff = 80 # adjust if necessary\n",
    "\n",
    "func = fuzzy_lookup_simple_id\n",
    "## default setting: match author by CBDB id\n",
    "\n",
    "# func = fuzzy_lookup_by_id\n",
    "# match author by CBDB id AND if no match by id, check against works with no known author (c_name_chn = 未詳)\n",
    "\n",
    "# func = fuzzy_lookup_by_name\n",
    "## match author by Chinese character AND if no match by author name, check against works with no known author (c_name_chn = 未詳)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27b5653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_merge(func, inputtable, comparetable, comparecols, inputcols, scorer, score_cutoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
